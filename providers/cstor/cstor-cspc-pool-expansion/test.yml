---
- hosts: localhost
  connection: local

  vars_files:
    - test_vars.yml

  tasks:
    - block:

         ## Generating the testname for deployment
        - include_tasks: /utils/fcm/create_testname.yml

         ## RECORD START-OF-TEST IN LITMUS RESULT CR
        - include_tasks: "/utils/fcm/update_litmus_result_resource.yml"
          vars:
            status: 'SOT'

        - name: Getting the compute node name
          shell: kubectl get nodes --no-headers | grep -v master | awk {'print $1'}
          register: nodes

        - name: Obtain the CSPI name to verify the status
          shell: >
            kubectl get cspi -n {{ operator_ns}} -l openebs.io/cstor-pool-cluster={{ pool_name }} 
            -o custom-columns=:.metadata.name --no-headers
          args:
            executable: /bin/bash
          register: cspi_name

        - name: Obtain the CSPI size before expand the pool
          shell: >
            kubectl get cspi -n {{ operator_ns}} -l openebs.io/cstor-pool-cluster={{ pool_name }}
            -o custom-columns=:.status.capacity.total --no-headers | tr -d G
          args:
            executable: /bin/bash
          register: cspi_bfr_expansion

        - name: set the value for the disk count to fetch the unclaimed blockDevice from each node
          set_fact:
            disk_count: "{{ item.value.count }}"
          loop: "{{ lookup('dict', bd_count) }}"
          when: "'{{ pool_type }}' in item.key"

        # Creating the blockdevice template from blockdevice.j2 jinja template for each node
        - name: Add node labels for each nodes and create blockdevice template
          template:
            src: ./blockdevice.j2
            dest: ./blockdevice-{{ item[0] }}.yml
          with_together:
            - "{{ nodes.stdout_lines }}"

        - name: Add the block devices for each node's block device template
          include_tasks: add_blockdevice.yml
          with_items: "{{ nodes.stdout_lines }}"
          loop_control:
            loop_var: outer_item

        # Insert the blockdevice template created for each nodes into cspc spec
        # blockinfile module will insert the external_files/block.
        # marker line template will be replaced with the values in marker_begin (default="BEGIN") and marker_end (default="END").
        - name: Include the blockdevice template in the CSPC spec
          blockinfile:
            dest: ./cspc.yml
            marker_end: "## {{ item }} Ansible Config ##"
            insertafter: pools
            state: present
            block: |
              {{ lookup('file', './blockdevice-{{ item }}.yml') }}
          with_items:
            - "{{ nodes.stdout_lines }}"

        - name: Replacing the pool group id in CSPC spec
          replace:
            path: ./cspc.yml
            regexp: "pool-name"
            replace: "{{ pool_name }}"

        - name: Replacing the namespace in CSPC spec
          replace:
            path: ./cspc.yml
            regexp: "operator_ns"
            replace: "{{ operator_ns }}"

        - name: Replacing the pool type in CSPC spec
          replace:
            path: ./cspc.yml
            regexp: "pool-type"
            replace: "{{ pool_type }}"

        - name: Add node labels for each nodes and create blockdevice template
          template:
            src: expand-block-devices.j2
            dest: expand-block-devices-{{ item[0] }}.yml
          with_together:
             - "{{ nodes.stdout_lines }}"

        - name: Add the block devices for each node's block device template
          include_tasks: expand_blockdevice.yml
          with_items: "{{ nodes.stdout_lines }}"
          loop_control:
            loop_var: outer_item

        - name: Display cspc.yml for verification 
          debug: var=item
          with_file:
          - "cspc.yml"

        - name: Expand the cstor disk pool
          shell: kubectl apply -f cspc.yml
          args:
            executable: /bin/bash

        - name: Verify the status of CSPI
          shell: >
            kubectl get cspi -n {{ operator_ns }} -o jsonpath='{.items[?(@.metadata.name=="{{ item }}")].status.phase}'
          args:
            executable: /bin/bash
          register: cspi_status
          with_items: "{{ cspi_name.stdout_lines }}"
          until: "'ONLINE' in cspi_status.stdout"
          delay: 5
          retries: 30

        - name: Verify if cStor Pool are Running
          shell: >
            kubectl get pods -n {{ operator_ns }} -l openebs.io/cstor-pool-instance={{ item }}
            --no-headers -o custom-columns=:status.phase
          args:
            executable: /bin/bash
          register: pool_count
          with_items: "{{ cspi_name.stdout_lines }}"
          until: "((pool_count.stdout_lines|unique)|length) == 1 and 'Running' in pool_count.stdout"
          retries: 30
          delay: 10

        - name: sleep for 120 seconds and continue with play
          wait_for: timeout=120

        - name: Obtain the CSPI size after expand the pool
          shell: >
            kubectl get cspi -n {{ operator_ns}} -l openebs.io/cstor-pool-cluster={{ pool_name }}
            -o custom-columns=:.status.capacity.total --no-headers | tr -d G
          args:
            executable: /bin/bash
          register: cspi_after_expansion

        - name: check if the CSPC pool has been expanded
          shell: if (( $(echo "{{ item[1] }} > {{ item[0] }}" | bc -l) )) ; then echo "pass"; else echo "fail";fi;
          args:
            executable: /bin/bash
          register: pool_status
          failed_when: "'pass' not in pool_status.stdout"
          with_together:
             - "{{ cspi_bfr_expansion.stdout_lines }}"
             - "{{ cspi_after_expansion.stdout_lines }}"

        - set_fact:
            flag: "Pass"
    
      rescue:
          - set_fact:
              flag: "Fail"
  
      always:
            ## RECORD END-OF-TEST IN LITMUS RESULT CR
          - include_tasks: /utils/fcm/update_litmus_result_resource.yml
            vars:
              status: 'EOT'
