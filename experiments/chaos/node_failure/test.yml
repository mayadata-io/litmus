---
- hosts: localhost
  connection: local

  vars_files:
    - test_vars.yml
    - /mnt/parameters.yml

  tasks:

    - block:

        - include_tasks: /utils/fcm/create_testname.yml

        - include_tasks: /utils/fcm/update_litmus_result_resource.yml
          vars:
            status: 'SOT'
            chaostype: "node-failure"
            app: ""

        ## DISPLAY APP INFORMATION
        - name: Display the app information passed via the test job
          debug:
            msg:
              - "The application info is as follows:"
              - "Namespace    : {{ namespace }}"
              - "Label        : {{ label }}"

        - name: Identify the chaos util to be invoked
          template:
            src: chaosutil.j2
            dest: chaosutil.yml

        - include_vars:
            file: chaosutil.yml

        - name: Record the chaos util path
          set_fact:
            chaos_util_path: "/{{ chaosutil }}"

        - name: Identify the data consistency util to be invoked
          template:
            src: data_persistence.j2
            dest: data_persistence.yml

        - include_vars:
            file: data_persistence.yml

        - name: Record the data consistency util path
          set_fact:
            data_consistency_util_path: "{{ consistencyutil }}"
          when: data_persistence != ''

        ## Verify the APPLICATION UNDER TEST PRE CHAOS
        - name: Verify if the application is running.
          include_tasks: /utils/k8s/status_app_pod.yml
          vars:
            app_ns: "{{ namespace }}"
            app_lkey: "{{ label.split('=')[0] }}"
            app_lvalue: "{{ label.split('=')[1] }}"
            delay: '2'
            retries: '60'

        ## Fetch application pod name
        - name: Get application pod name
          shell: >
            kubectl get pod -n {{ namespace }} -l {{ label }} --no-headers -o=custom-columns=NAME:".metadata.name"
          args:
            executable: /bin/bash
          register: app_pod_name

        ## Generate data on the application
        - name: Generate data on the specified application.
          include: "{{ data_consistency_util_path }}"
          vars:
            status: 'LOAD'
            ns: "{{ namespace }}"
            pod_name: "{{ app_pod_name.stdout }}"
          when: data_persistence != ''

        ## Obtain the node where application pod is running
        - name: Get Application pod Node to perform chaos
          shell: >
            kubectl get pod {{ app_pod_name.stdout }} -n {{ namespace }}
            --no-headers -o custom-columns=:spec.nodeName
          args:
            executable: /bin/bash
          register: app_node

        ## Execute the chaos util to turn off the target node
        - include_tasks: "{{ chaos_util_path }}"
          vars:
            esx_ip: "{{ host_ip }}"
            target_node: "{{ app_node.stdout }}"
            operation: "off"
          when: platform == 'vmware'

        - name: Check the node status
          shell: kubectl get nodes {{ app_node.stdout }} --no-headers
          args:
            executable: /bin/bash
          register: state
          until: "'NotReady' in state.stdout"
          delay: 30
          retries: 15

        # wait 5 minutes
        - name: Wait for the application pod to get evicted
          wait_for:
            timeout: 300

        ## Application verification after injecting chaos
        - include_tasks: /utils/k8s/status_app_pod.yml
          vars:
            app_ns: "{{ namespace }}"
            app_lkey: "{{ label.split('=')[0] }}"
            app_lvalue: "{{ label.split('=')[1] }}"
            delay: '2'
            retries: '150'

        - name: Check if the application pod is rescheduled
          shell: >
            kubectl get pods -n {{ namespace }} -l {{ label }} --no-headers
            -o wide | grep -v {{ app_node.stdout }} | awk '{print $3}'
          args:
            executable: /bin/bash
          register: rescheduled_app_pod
          until: "'Running' in rescheduled_app_pod.stdout"
          delay: 10
          retries: 30

        - name: Verify application data persistence
          include: "{{ data_consistency_util_path }}"
          vars:
            status: 'VERIFY'
            ns: "{{ namespace }}"
            pod_name: "{{ rescheduled_app_pod.stdout }}"
          when: data_persistence != ''

        - set_fact:
            flag: "Pass"

      rescue:
        - set_fact:
            flag: "Fail"

      always:

        - name: Get the pending pod
          shell: >
            kubectl get po -n {{ namespace }} -l app=node-failure-cstor --no-headers | grep -v {{ app_pod_name.stdout }} | awk '{print $1}'
          args:
            executable: /bin/bash
          register: test
   
        - name: describe the pending pod
          shell: >
            kubectl describe po {{ test.stdout }} -n {{ namespace }}
          args:
            executable: /bin/bash

        # Turn on the k8s node
        - include_tasks: "{{ chaos_util_path }}"
          vars:
            esx_ip: "{{ host_ip }}"
            target_node: "{{ app_node.stdout }}"
            operation: "on"
          when: platform == 'vmware'

        - include_tasks: /utils/fcm/update_litmus_result_resource.yml
          vars:
            status: 'EOT'
            chaostype: "node-failure"
            app: ""
